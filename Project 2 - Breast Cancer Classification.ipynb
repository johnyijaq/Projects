{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "straight-transformation",
   "metadata": {},
   "source": [
    "Author: **Johny Ijaq**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "architectural-astronomy",
   "metadata": {},
   "source": [
    "# BREAST CANCER CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-position",
   "metadata": {},
   "source": [
    "### Dataset Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portuguese-jenny",
   "metadata": {},
   "source": [
    "This is a classic breast cancer dataset from UCI machinery repository. In this dataset each row corresponds to a patient and each column correspnds to different features that determine whether the tumor is benign or malignant. If the tumour is benign, class takes the value of two and if the tumour is malignant, class takes a value of four.\n",
    "\n",
    "**Objective:** Main aim of this problem is to deploy different classification models and figure out which one performed better in predicting whether the given tumour is benign or malignant.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convertible-professor",
   "metadata": {},
   "source": [
    "## 1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "brave-expense",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advance-financing",
   "metadata": {},
   "source": [
    "## 2. Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "extra-round",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "lyric-sunglasses",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample code number</th>\n",
       "      <th>Clump Thickness</th>\n",
       "      <th>Uniformity of Cell Size</th>\n",
       "      <th>Uniformity of Cell Shape</th>\n",
       "      <th>Marginal Adhesion</th>\n",
       "      <th>Single Epithelial Cell Size</th>\n",
       "      <th>Bare Nuclei</th>\n",
       "      <th>Bland Chromatin</th>\n",
       "      <th>Normal Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sample code number  Clump Thickness  Uniformity of Cell Size  \\\n",
       "0             1000025                5                        1   \n",
       "1             1002945                5                        4   \n",
       "2             1015425                3                        1   \n",
       "3             1016277                6                        8   \n",
       "4             1017023                4                        1   \n",
       "\n",
       "   Uniformity of Cell Shape  Marginal Adhesion  Single Epithelial Cell Size  \\\n",
       "0                         1                  1                            2   \n",
       "1                         4                  5                            7   \n",
       "2                         1                  1                            2   \n",
       "3                         8                  1                            3   \n",
       "4                         1                  3                            2   \n",
       "\n",
       "   Bare Nuclei  Bland Chromatin  Normal Nucleoli  Mitoses  Class  \n",
       "0            1                3                1        1      2  \n",
       "1           10                3                2        1      2  \n",
       "2            2                3                1        1      2  \n",
       "3            4                3                7        1      2  \n",
       "4            1                3                1        1      2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "pleasant-depression",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 683 entries, 0 to 682\n",
      "Data columns (total 11 columns):\n",
      " #   Column                       Non-Null Count  Dtype\n",
      "---  ------                       --------------  -----\n",
      " 0   Sample code number           683 non-null    int64\n",
      " 1   Clump Thickness              683 non-null    int64\n",
      " 2   Uniformity of Cell Size      683 non-null    int64\n",
      " 3   Uniformity of Cell Shape     683 non-null    int64\n",
      " 4   Marginal Adhesion            683 non-null    int64\n",
      " 5   Single Epithelial Cell Size  683 non-null    int64\n",
      " 6   Bare Nuclei                  683 non-null    int64\n",
      " 7   Bland Chromatin              683 non-null    int64\n",
      " 8   Normal Nucleoli              683 non-null    int64\n",
      " 9   Mitoses                      683 non-null    int64\n",
      " 10  Class                        683 non-null    int64\n",
      "dtypes: int64(11)\n",
      "memory usage: 58.8 KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cloudy-notebook",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(683, 11)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "confused-google",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample code number</th>\n",
       "      <th>Clump Thickness</th>\n",
       "      <th>Uniformity of Cell Size</th>\n",
       "      <th>Uniformity of Cell Shape</th>\n",
       "      <th>Marginal Adhesion</th>\n",
       "      <th>Single Epithelial Cell Size</th>\n",
       "      <th>Bare Nuclei</th>\n",
       "      <th>Bland Chromatin</th>\n",
       "      <th>Normal Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.830000e+02</td>\n",
       "      <td>683.000000</td>\n",
       "      <td>683.000000</td>\n",
       "      <td>683.000000</td>\n",
       "      <td>683.000000</td>\n",
       "      <td>683.000000</td>\n",
       "      <td>683.000000</td>\n",
       "      <td>683.000000</td>\n",
       "      <td>683.000000</td>\n",
       "      <td>683.000000</td>\n",
       "      <td>683.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.076720e+06</td>\n",
       "      <td>4.442167</td>\n",
       "      <td>3.150805</td>\n",
       "      <td>3.215227</td>\n",
       "      <td>2.830161</td>\n",
       "      <td>3.234261</td>\n",
       "      <td>3.544656</td>\n",
       "      <td>3.445095</td>\n",
       "      <td>2.869693</td>\n",
       "      <td>1.603221</td>\n",
       "      <td>2.699854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.206440e+05</td>\n",
       "      <td>2.820761</td>\n",
       "      <td>3.065145</td>\n",
       "      <td>2.988581</td>\n",
       "      <td>2.864562</td>\n",
       "      <td>2.223085</td>\n",
       "      <td>3.643857</td>\n",
       "      <td>2.449697</td>\n",
       "      <td>3.052666</td>\n",
       "      <td>1.732674</td>\n",
       "      <td>0.954592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.337500e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.776170e+05</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.171795e+06</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.238705e+06</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.345435e+07</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sample code number  Clump Thickness  Uniformity of Cell Size  \\\n",
       "count        6.830000e+02       683.000000               683.000000   \n",
       "mean         1.076720e+06         4.442167                 3.150805   \n",
       "std          6.206440e+05         2.820761                 3.065145   \n",
       "min          6.337500e+04         1.000000                 1.000000   \n",
       "25%          8.776170e+05         2.000000                 1.000000   \n",
       "50%          1.171795e+06         4.000000                 1.000000   \n",
       "75%          1.238705e+06         6.000000                 5.000000   \n",
       "max          1.345435e+07        10.000000                10.000000   \n",
       "\n",
       "       Uniformity of Cell Shape  Marginal Adhesion  \\\n",
       "count                683.000000         683.000000   \n",
       "mean                   3.215227           2.830161   \n",
       "std                    2.988581           2.864562   \n",
       "min                    1.000000           1.000000   \n",
       "25%                    1.000000           1.000000   \n",
       "50%                    1.000000           1.000000   \n",
       "75%                    5.000000           4.000000   \n",
       "max                   10.000000          10.000000   \n",
       "\n",
       "       Single Epithelial Cell Size  Bare Nuclei  Bland Chromatin  \\\n",
       "count                   683.000000   683.000000       683.000000   \n",
       "mean                      3.234261     3.544656         3.445095   \n",
       "std                       2.223085     3.643857         2.449697   \n",
       "min                       1.000000     1.000000         1.000000   \n",
       "25%                       2.000000     1.000000         2.000000   \n",
       "50%                       2.000000     1.000000         3.000000   \n",
       "75%                       4.000000     6.000000         5.000000   \n",
       "max                      10.000000    10.000000        10.000000   \n",
       "\n",
       "       Normal Nucleoli     Mitoses       Class  \n",
       "count       683.000000  683.000000  683.000000  \n",
       "mean          2.869693    1.603221    2.699854  \n",
       "std           3.052666    1.732674    0.954592  \n",
       "min           1.000000    1.000000    2.000000  \n",
       "25%           1.000000    1.000000    2.000000  \n",
       "50%           1.000000    1.000000    2.000000  \n",
       "75%           4.000000    1.000000    4.000000  \n",
       "max          10.000000   10.000000    4.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "saved-indian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sample code number             0\n",
       "Clump Thickness                0\n",
       "Uniformity of Cell Size        0\n",
       "Uniformity of Cell Shape       0\n",
       "Marginal Adhesion              0\n",
       "Single Epithelial Cell Size    0\n",
       "Bare Nuclei                    0\n",
       "Bland Chromatin                0\n",
       "Normal Nucleoli                0\n",
       "Mitoses                        0\n",
       "Class                          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sticky-cologne",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bored-spotlight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1000025       5       1 ...       3       1       1]\n",
      " [1002945       5       4 ...       3       2       1]\n",
      " [1015425       3       1 ...       3       1       1]\n",
      " ...\n",
      " [ 888820       5      10 ...       8      10       2]\n",
      " [ 897471       4       8 ...      10       6       1]\n",
      " [ 897471       4       8 ...      10       4       1]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "leading-organization",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2 2 4 2 2 2 2 2 2 4 2 4 4 2 2 4 2 4 4 2 2 4 2 2 2 2 2 2 4 2 2 2 4 2\n",
      " 4 4 4 4 4 4 2 4 2 2 4 4 4 4 4 4 4 4 4 4 4 4 2 4 4 2 4 2 4 4 2 2 4 2 4 4 2\n",
      " 2 2 2 2 2 2 2 2 4 4 4 4 2 2 2 2 2 2 2 2 2 2 4 4 4 4 2 4 4 4 4 4 2 4 2 4 4\n",
      " 4 2 2 2 4 2 2 2 2 4 4 4 2 4 2 4 2 2 2 4 2 2 2 2 2 2 2 2 4 2 2 4 2 2 4 2 4\n",
      " 4 2 2 4 2 2 4 4 2 2 2 2 4 4 2 2 2 2 2 4 4 4 2 4 2 4 2 2 2 4 4 2 4 4 4 2 4\n",
      " 4 2 2 2 2 2 2 2 2 4 4 2 2 2 4 4 2 2 2 4 4 2 4 4 4 2 2 4 2 2 4 4 4 4 2 4 4\n",
      " 2 4 4 4 2 4 2 4 4 4 4 2 2 2 2 2 2 4 4 2 2 4 2 4 4 4 2 2 2 2 4 4 4 4 4 2 4\n",
      " 4 4 2 4 2 4 4 2 2 2 2 4 2 2 4 4 4 4 4 2 4 4 2 2 4 4 2 2 4 4 2 4 2 4 4 2 2\n",
      " 4 2 2 2 4 2 2 4 4 2 2 4 2 4 2 2 4 2 4 4 4 2 2 4 4 2 4 2 2 4 4 2 2 2 4 2 2\n",
      " 2 4 4 2 2 2 4 2 2 4 4 4 4 4 4 2 2 2 2 4 4 2 2 2 2 2 2 2 2 2 2 2 2 2 4 2 2\n",
      " 2 2 4 2 2 2 2 4 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 2 2 2 2 4 2 4 2 4 2 2 2 2 4\n",
      " 2 2 2 4 2 4 2 2 2 2 2 2 2 4 4 2 2 2 4 2 2 2 2 2 2 2 2 4 2 2 2 4 2 4 4 4 2\n",
      " 2 2 2 2 2 2 4 4 4 2 2 2 2 2 2 2 2 2 2 2 4 2 2 4 4 2 2 2 4 4 4 2 4 2 4 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 2 4 4 2 2 2 4 2 2 4 4 2 2 2 2 2 2 4 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 4 2 2 4 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 4 2 2 4 4\n",
      " 4 4 2 2 4 2 2 2 2 2 2 4 4 2 2 2 4 2 4 2 4 4 4 2 4 2 2 2 2 2 2 2 2 4 4 4 2\n",
      " 2 4 2 4 4 4 2 2 2 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 4 2 2 4 2 2 2 2 2 2 2 2\n",
      " 2 2 2 4 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 2 2 2 4 4 4 2 2 2 2 2 2 2 2 2 4 4\n",
      " 2 2 2 2 2 2 2 2 2 4 2 2 2 2 4 4 4]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worth-leonard",
   "metadata": {},
   "source": [
    "## 3. Splitting the Dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "stable-concern",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "artistic-exhibit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(546, 10)\n",
      "(137, 10)\n",
      "(546,)\n",
      "(137,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ruled-texture",
   "metadata": {},
   "source": [
    "## 4. Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "passive-douglas",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "resident-establishment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.58169832  2.02339612  2.2251362  ... -0.19098898  0.69366865\n",
      "  -0.33423456]\n",
      " [ 0.58252832 -0.13858878 -0.70631669 ... -0.99623981 -0.61686105\n",
      "  -0.33423456]\n",
      " [-2.70801546  0.22174204  2.2251362  ...  2.62738894  1.02130107\n",
      "   1.97579166]\n",
      " ...\n",
      " [-0.10772048 -0.85925041 -0.70631669 ... -0.19098898 -0.61686105\n",
      "  -0.33423456]\n",
      " [ 0.6109826  -1.21958122 -0.70631669 ... -0.5936144  -0.61686105\n",
      "  -0.33423456]\n",
      " [-0.82630647  2.02339612 -0.05488272 ...  1.41951269  1.02130107\n",
      "  -0.33423456]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "quick-court",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.72378104e-02 -2.25754806e-01 -6.85929021e-01 ... -5.78597638e-01\n",
      "  -5.97316414e-01 -4.05688531e-01]\n",
      " [ 1.08528169e-02 -1.23428986e+00 -6.85929021e-01 ... -1.01413542e+00\n",
      "  -5.97316414e-01  3.06801952e+00]\n",
      " [ 4.33939854e-03  1.79131531e+00  2.28161653e+00 ...  2.03462906e+00\n",
      "   2.36047932e+00 -4.05688531e-01]\n",
      " ...\n",
      " [ 8.12199415e-02 -1.23428986e+00 -6.85929021e-01 ... -1.43059855e-01\n",
      "  -5.97316414e-01 -4.05688531e-01]\n",
      " [ 2.83992661e-02  1.10423546e-01 -6.85929021e-01 ... -1.43059855e-01\n",
      "  -5.97316414e-01 -4.05688531e-01]\n",
      " [ 9.80167883e+00 -1.23428986e+00 -6.85929021e-01 ... -5.78597638e-01\n",
      "  -5.97316414e-01 -4.05688531e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sitting-warren",
   "metadata": {},
   "source": [
    "## 5. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thermal-environment",
   "metadata": {},
   "source": [
    "### 5.1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "worldwide-kelly",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression(random_state = 0)\n",
    "log_reg.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinated-smell",
   "metadata": {},
   "source": [
    "### 5.2. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ignored-theme",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear', random_state=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_classifier = SVC(kernel = \"linear\", random_state = 0)\n",
    "svm_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rising-donor",
   "metadata": {},
   "source": [
    "### 5.3. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "third-piece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors = 5, metric = \"minkowski\", p = 2)\n",
    "knn_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brutal-ukraine",
   "metadata": {},
   "source": [
    "### 5.4. Kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dangerous-saturn",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(random_state=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "kernel_svm = SVC(kernel = \"rbf\", random_state = 0)\n",
    "kernel_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessory-salem",
   "metadata": {},
   "source": [
    "### 5.5. Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "excess-remainder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "english-dealer",
   "metadata": {},
   "source": [
    "### 5.6. Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "least-mounting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', random_state=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(criterion = \"entropy\", random_state = 0)\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classical-strength",
   "metadata": {},
   "source": [
    "### 5.7. Random Forest Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "standard-sterling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', n_estimators=10, random_state=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators = 10, criterion = \"entropy\", random_state = 0)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sonic-hardwood",
   "metadata": {},
   "source": [
    "### 5.8. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bacterial-investigator",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install -c conda-forge xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "figured-orange",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.4.1-py3-none-win_amd64.whl (97.8 MB)\n",
      "Requirement already satisfied: scipy in c:\\users\\johny\\anaconda3\\lib\\site-packages (from xgboost) (1.5.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\johny\\anaconda3\\lib\\site-packages (from xgboost) (1.19.2)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "awful-career",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:58:13] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier() \n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-unknown",
   "metadata": {},
   "source": [
    "# 6.Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unnecessary-burke",
   "metadata": {},
   "source": [
    "### 6.1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "widespread-reunion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[87  0]\n",
      " [ 4 46]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9708029197080292"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred_log_reg)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred_log_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orange-awareness",
   "metadata": {},
   "source": [
    "### 6.2. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "saving-patio",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[86  1]\n",
      " [ 4 46]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9635036496350365"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "y_pred_svm_classifier = svm_classifier.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred_svm_classifier)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred_svm_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chronic-pipeline",
   "metadata": {},
   "source": [
    "#### Applying K-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "hundred-maker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.70 %\n",
      "Standard Deviation: 1.61 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = svm_classifier, X = X_train, y = y_train, cv = 10)\n",
    "print(\"Accuracy: {:.2f} %\" .format(accuracies.mean()*100))\n",
    "print(\"Standard Deviation: {:.2f} %\" .format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innovative-warrant",
   "metadata": {},
   "source": [
    "### 6.3. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "spread-sunset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[86  1]\n",
      " [ 5 45]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9562043795620438"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "y_pred_knn_classifier = knn_classifier.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred_knn_classifier)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred_knn_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "timely-scoop",
   "metadata": {},
   "source": [
    "### 6.4. Kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "silent-papua",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[83  4]\n",
      " [ 4 46]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9416058394160584"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "y_pred_kernel_svm = kernel_svm.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred_kernel_svm)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred_kernel_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monetary-shelter",
   "metadata": {},
   "source": [
    "### 6.5. Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "forced-recycling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[83  4]\n",
      " [ 4 46]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9416058394160584"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "y_pred_nb = nb.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred_nb)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wireless-holmes",
   "metadata": {},
   "source": [
    "### 6.6. Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "arabic-egyptian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[85  2]\n",
      " [ 8 42]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.927007299270073"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred_dt)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional-prize",
   "metadata": {},
   "source": [
    "### 6.7. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "funky-necessity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[86  1]\n",
      " [ 4 46]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9635036496350365"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "y_pred_rf = rf. predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred_rf)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "curious-power",
   "metadata": {},
   "source": [
    "### 6.8. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "crucial-things",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[86  1]\n",
      " [ 5 45]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9562043795620438"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred_xgb)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "growing-sense",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy from Logistic Regression:       97.08\n",
      "Accuracy from SVM Classifier:            96.35\n",
      "Accuracy from KNN Classifier:            95.62\n",
      "Accuracy from Kernel SVM:                94.16\n",
      "Accuracy from Naive Bayes Classifier:    94.16\n",
      "Accuracy from Decision Tree Classifier:  92.70\n",
      "Accuracy from Random Forest Classifier:  96.35\n",
      "Accuracy from XGBoost Classifier:        95.62\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy from Logistic Regression:       {:.2f}\" .format(accuracy_score(y_test, y_pred_log_reg)*100))\n",
    "print(\"Accuracy from SVM Classifier:            {:.2f}\" .format(accuracy_score(y_test, y_pred_svm_classifier)*100))\n",
    "print(\"Accuracy from KNN Classifier:            {:.2f}\" .format (accuracy_score(y_test, y_pred_knn_classifier)*100))\n",
    "print(\"Accuracy from Kernel SVM:                {:.2f}\" .format(accuracy_score(y_test, y_pred_kernel_svm)*100))\n",
    "print(\"Accuracy from Naive Bayes Classifier:    {:.2f}\" .format (accuracy_score(y_test, y_pred_nb)*100))\n",
    "print(\"Accuracy from Decision Tree Classifier:  {:.2f}\" .format(accuracy_score(y_test, y_pred_dt)*100))\n",
    "print(\"Accuracy from Random Forest Classifier:  {:.2f}\" .format(accuracy_score(y_test, y_pred_rf)*100))\n",
    "print(\"Accuracy from XGBoost Classifier:        {:.2f}\" .format(accuracy_score(y_test, y_pred_xgb)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inner-groove",
   "metadata": {},
   "source": [
    "Logistic regression has shown highest accuracy followed by SVM and Random Forest. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lined-guatemala",
   "metadata": {},
   "source": [
    "## 7. Applying K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "stunning-houston",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:08:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:08:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:08:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:08:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:08:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:08:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:08:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:08:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:08:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:08:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      "\n",
      "Accuracy from Logistic Regression:       96.34 %\n",
      "Standard Deviation:                      2.02 %\n",
      "\n",
      "\n",
      "Accuracy from SVM Classifier:            96.70 %\n",
      "Standard Deviation:                      1.61 %\n",
      "\n",
      "\n",
      "Accuracy from KNN Classifier:            96.52 %\n",
      "Standard Deviation:                      2.09 %\n",
      "\n",
      "\n",
      "Accuracy from Kernel SVM:                96.70 %\n",
      "Standard Deviation:                      1.81 %\n",
      "\n",
      "\n",
      "Accuracy from Naive Bayes Classifier:    96.33 %\n",
      "Standard Deviation:                      2.33 %\n",
      "\n",
      "\n",
      "Accuracy from Decision Tree Classifier:  95.05 %\n",
      "Standard Deviation:                      2.61 %\n",
      "\n",
      "\n",
      "Accuracy from Random Forest Classifier:  95.60 %\n",
      "Standard Deviation:                      1.68 %\n",
      "\n",
      "\n",
      "Accuracy from XGBoost:                   96.52 %\n",
      "Standard Deviation:                      1.72 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#logistic regression\n",
    "accuracies_log_reg = cross_val_score(estimator = log_reg, X = X_train, y = y_train, cv = 10)\n",
    "\n",
    "#SVM\n",
    "accuracies_svm = cross_val_score(estimator = svm_classifier, X = X_train, y = y_train, cv = 10)\n",
    "\n",
    "#knn\n",
    "accuracies_knn = cross_val_score(estimator = knn_classifier, X = X_train, y = y_train, cv = 10)\n",
    "\n",
    "#Kernel SVM\n",
    "accuracies_kernel_svm = cross_val_score(estimator = kernel_svm, X = X_train, y = y_train, cv = 10)\n",
    "\n",
    "#Naive Bayes\n",
    "accuracies_nb = cross_val_score(estimator = nb, X = X_train, y = y_train, cv = 10)\n",
    "\n",
    "#Decision Tree Classifier\n",
    "accuracies_dt = cross_val_score(estimator = dt, X = X_train, y = y_train, cv = 10)\n",
    "\n",
    "#Random Forest\n",
    "accuracies_rf = cross_val_score(estimator = rf, X = X_train, y = y_train, cv = 10)\n",
    "\n",
    "#XGBoost\n",
    "accuracies_xgb = cross_val_score(estimator = xgb, X= X_train, y = y_train, cv = 10)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy from Logistic Regression:       {:.2f} %\" .format(accuracies_log_reg.mean()*100))\n",
    "print(\"Standard Deviation:                      {:.2f} %\" .format(accuracies_log_reg.std()*100))\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy from SVM Classifier:            {:.2f} %\" .format(accuracies_svm.mean()*100))\n",
    "print(\"Standard Deviation:                      {:.2f} %\" .format(accuracies_svm.std()*100))\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy from KNN Classifier:            {:.2f} %\" .format(accuracies_knn.mean()*100))\n",
    "print(\"Standard Deviation:                      {:.2f} %\" .format(accuracies_knn.std()*100))\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy from Kernel SVM:                {:.2f} %\" .format(accuracies_kernel_svm.mean()*100))\n",
    "print(\"Standard Deviation:                      {:.2f} %\" .format(accuracies_kernel_svm.std()*100))\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy from Naive Bayes Classifier:    {:.2f} %\" .format(accuracies_nb.mean()*100))\n",
    "print(\"Standard Deviation:                      {:.2f} %\" .format(accuracies_nb.std()*100))\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy from Decision Tree Classifier:  {:.2f} %\" .format(accuracies_dt.mean()*100))\n",
    "print(\"Standard Deviation:                      {:.2f} %\" .format(accuracies_dt.std()*100))\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy from Random Forest Classifier:  {:.2f} %\" .format(accuracies_rf.mean()*100))\n",
    "print(\"Standard Deviation:                      {:.2f} %\" .format(accuracies_rf.std()*100))\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy from XGBoost:                   {:.2f} %\" .format(accuracies_xgb.mean()*100))\n",
    "print(\"Standard Deviation:                      {:.2f} %\" .format(accuracies_xgb.std()*100))\n",
    "\n",
    "\n",
    "#print(\"Standard Deviation_Logistic Regression: {:.2f} %\" .format(accuracies_log_reg.std()*100))\n",
    "#print(\"Standard Deviation_SVM Classifier:      {:.2f} %\" .format(accuracies_svm.std()*100))\n",
    "#print(\"Standard Deviation_KNN Classifier:      {:.2f} %\" .format(accuracies_knn.std()*100))\n",
    "#print(\"Standard Deviation_Kernel_SVM:          {:.2f} %\" .format(accuracies_kernel_svm.std()*100))\n",
    "#print(\"Standard Deviation_Naive Bayes:         {:.2f} %\" .format(accuracies_nb.std()*100))\n",
    "#print(\"Standard Deviation_Decision Tree:       {:.2f} %\" .format(accuracies_dt.std()*100))\n",
    "#print(\"Standard Deviation_Random Forest:       {:.2f} %\" .format(accuracies_rf.std()*100))\n",
    "#print(\"Standard Deviation_ XGBoost:            {:.2f} %\" .format(accuracies_xgb.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-airport",
   "metadata": {},
   "source": [
    "Applying 10 fold cross validation has improved the accuracies of all the models, except logistic regression.  \n",
    "\n",
    "Overall, **logistic regression model** has performed better in predicting whether the given tumor is beingn or malignant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understood-animal",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
